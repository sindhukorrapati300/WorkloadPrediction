{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce037e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import poisson\n",
    "import statistics\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "import torch\n",
    "from torch import optim\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.modules.loss\n",
    "from torch.distributions import Categorical, Normal, Dirichlet\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65026ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Trace Loading Alibaba Trace 2018 with 5 Task Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load workload trace\n",
    "df1=pd.read_csv('alibaba_2018_taskdomains_topics_5_1.csv',sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d250238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 contains Unnamed:0, CPU_util, mem_util, net_in, net_out and Task Domain\\n\",\n",
    "del df1['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['CPU_util','mem_util','net_in','net_out','disk','Task Domain']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f804508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If any column contains null values, then drop null values\n",
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data without task domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc7522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual = df1[['CPU_util','mem_util','net_in','net_out','disk']].copy()\n",
    "#norm = MinMaxScaler()\n",
    "#act_correct = pd.DataFrame(norm.fit_transform(df_actual), columns=df_actual.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae74b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_correct = df_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab70bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Task Domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f1eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now add taskdomain to data\n",
    "act_correct['Task Domain'] = df1['Task Domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954f0cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b8972",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=act_correct['Task Domain']\n",
    "la=label.tolist()\n",
    "#w_len=len(la)\n",
    "la1=la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and Test Split\n",
    "# Define the split ratio (e.g., 80% train, 20% test)\n",
    "split_ratio = 0.8\n",
    "# Calculate the number of samples for the train and test splits\n",
    "train_size = int(split_ratio * len(act_correct))\n",
    "test_size = len(act_correct) - train_size\n",
    "# Split the labels into train and test sets based on the split ratio\n",
    "train_data = la1[:train_size]\n",
    "w_len = len(train_data)\n",
    "l = 35\n",
    "no_of_partitions=math.ceil(w_len/l)\n",
    "test_data = la1[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709327f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating partitions from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba55a9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initial partitions\n",
    "split_lists = [train_data[x:x+l] for x in range(0, len(train_data), l)]\n",
    "#print(split_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d85f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score function for a partition\n",
    "def score_calc(lis):\n",
    "    return (2*modularity(lis,5)*likelihood_calc(lis))/(modularity(lis,5)+likelihood_calc(lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de82ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularity(lis,n):  \n",
    "    one_step_array=np.array(twostep_transition_matrix(lis))  \n",
    "    M_prime=[[1/n]*n for _ in range(n)]  \n",
    "    M_P=one_step_array-M_prime  \n",
    "    x=np.sum(M_P)  \n",
    "    m=np.sum(one_step_array)  \n",
    "    return x/m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df92ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representing each partition with markov model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efbaa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twostep_transition_matrix(transitions): \n",
    "    n = 5  # number of states\n",
    "    M = [[[0]*n for _ in range(n)] for _ in range(n)]\n",
    "    \n",
    "    for (i, j, k) in zip(transitions, transitions[1:], transitions[2:]): \n",
    "        M[i-1][j-1][k-1] += 1 \n",
    "\n",
    "    # Convert counts to probabilities with Laplace smoothing\n",
    "    for matrix in M:  \n",
    "        for row in matrix:\n",
    "            s = sum(row)\n",
    "            if s > 0:\n",
    "                row[:] = [(f + 1) / (s + n) for f in row]  # laplace smoothing\n",
    "    \n",
    "    return M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_calc(lis):\n",
    "    lambd = select_hyper(lis)\n",
    "    likelihood1 = 1\n",
    "    one_step_array = twostep_transition_matrix(lis)\n",
    "    \n",
    "    #print(\"Length of one_step_array:\", len(one_step_array))  # Print the length of the outer list\n",
    "    \n",
    "    for i in range(0, len(lis) - 2):  # Adjust the loop range for 3D matrix\n",
    "        #print(\"Index i:\", i)\n",
    "        #print(\"Indices:\", lis[i], lis[i+1], lis[i+2])\n",
    "        likelihood1 = likelihood1 * one_step_array[lis[i] - 1][lis[i+1] - 1][lis[i+2] - 1]  # Adjust indexing\n",
    "    \n",
    "    z = [[1] * 5 for _ in range(5)]  # 5 represents the number of task domains\n",
    "    for i in range(0, 5):\n",
    "        z[i] = lis.count(i + 1) + 1\n",
    "    s = 1\n",
    "    for i in range(0, len(z)):\n",
    "        s = s * poisson.pmf(z[i], lambd)\n",
    "    \n",
    "    return likelihood1 / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb9ca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Identifying correct partitions based on score function\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "partitions=[]\n",
    "flag = 0\n",
    "N = no_of_partitions\n",
    "j=0\n",
    "for i in range(0,no_of_partitions-1):\n",
    "    if flag == 0:\n",
    "        ps=l\n",
    "    x = score_calc(split_lists[i])\n",
    "    combined_list=[split_lists[i],split_lists[i+1]]\n",
    "   # print(combined_list)\n",
    "    merged_list=[item for sublist in combined_list for item in sublist]\n",
    "    y = score_calc(merged_list)\n",
    "    if abs(y-x) > 0.05:\n",
    "        flag = 1\n",
    "        #ps=len(split_lists[0])\n",
    "        split_lists[i+1].extend(split_lists[i])\n",
    "        ps=len(split_lists[i+1])\n",
    "        N = N-1\n",
    "    else:\n",
    "        flag = 0\n",
    "        partitions.append(ps)\n",
    "tot=np.sum(partitions)\n",
    "\n",
    "partitions.append(len(train_data)-tot)\n",
    "\n",
    "end_time = time.time()\n",
    "repetition_running_time_partition_create = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Set of Partitions\n",
    "from itertools import islice\n",
    "Inputt = iter(la)\n",
    "final_partitions = [list(islice(Inputt, elem))\n",
    "          for elem in partitions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad739022",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84cdf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_adj = [0 for _ in range(N)]\n",
    "norm = [0 for _ in range(N)]\n",
    "list_features = [0 for _ in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# Adjacency Matrix Construction for each partition\n",
    "for i in range(N):\n",
    "    list_adj[i] = np.array(twostep_transition_matrix(final_partitions[i]))\n",
    "    sum_adj = list_adj[i].sum()\n",
    "    if sum_adj == 0:\n",
    "        norm[i] = 1.0  # Set a default normalization value if the sum is zero\n",
    "    else:\n",
    "        norm[i] = list_adj[i].shape[0] * list_adj[i].shape[0] / float((list_adj[i].shape[0] * list_adj[i].shape[0] - sum_adj) * 2)\n",
    "    list_adj[i] = torch.from_numpy(np.array(twostep_transition_matrix(final_partitions[i]))).float()\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the total elapsed time\n",
    "total_running_time_partition = end_time - start_time\n",
    "print(\"Total running time for constructing\", len(partitions), \"matrices:\", total_running_time_partition, \"seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Adjacency Matrix Construction for each partition\n",
    "for i in range(N):\n",
    "    list_adj[i] = np.array(twostep_transition_matrix(final_partitions[i]))\n",
    "    sum_adj = list_adj[i].sum()\n",
    "    \n",
    "    if sum_adj == 0:\n",
    "        norm[i] = 1.0\n",
    "    else:\n",
    "        denominator = (list_adj[i].shape[0] * list_adj[i].shape[0] - sum_adj) * 2\n",
    "        if denominator != 0:\n",
    "            norm[i] = list_adj[i].shape[0] * list_adj[i].shape[0] / float(denominator)\n",
    "        else:\n",
    "            norm[i] = 0.0  # Set an appropriate value when denominator is zero\n",
    "            \n",
    "    list_adj[i] = torch.from_numpy(np.array(twostep_transition_matrix(final_partitions[i]))).float()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the total elapsed time\n",
    "total_running_time_partition = end_time - start_time\n",
    "print(\"Total running time for constructing\", len(partitions), \"matrices:\", total_running_time_partition, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging mean and variance vectors alternatively\n",
    "def countList(lst1, lst2):\n",
    "    return [sub[item] for item in range(len(lst2))\n",
    "                      for sub in [lst1, lst2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0622bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_correct['Task Domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484deb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Matrix Construction for each partition\n",
    "#cols = [3,4,5,6,8,10,11,12,13,14,15,16,17]\n",
    "j=0\n",
    "features = np.zeros((5,2*5))\n",
    "for j in range(0,5):\n",
    "    # If taskdomains are numbered from 0 write j and if task domains are numbered from 1 write j+1\n",
    "    rslt_df = df1.loc[df1['Task Domain'] == j] \n",
    "    #df_norm = rslt_df[rslt_df.columns[cols]]\n",
    "    #task1_df = rslt_df[rslt_df.columns[cols]]\n",
    "    task1_df = rslt_df[rslt_df.columns[0:5]]\n",
    "    norm = MinMaxScaler()\n",
    "    #applying norm to dataframe\n",
    "    df_norm = pd.DataFrame(norm.fit_transform(task1_df), columns=task1_df.columns)\n",
    "    #df_norm = df_norm.multiply(100)\n",
    "    sha = task1_df.shape\n",
    "    i=0\n",
    "    mea = [0]*sha[1]\n",
    "    var = [0]*sha[1]\n",
    "    for col in df_norm:\n",
    "        #print(col)\n",
    "        a = df_norm[col].to_numpy()\n",
    "        b = a[np.logical_not(np.isnan(a))]\n",
    "        mea[i]= statistics.mean(b)\n",
    "        var[i] = statistics.variance(b)\n",
    "        i = i+1\n",
    "    #features[j] = mea+var\n",
    "    features[j]=countList(mea, var)\n",
    "    #my_data = task1_df[col]\n",
    "    #ks_statistic, p_value = kstest(my_data, 'norm')\n",
    "    #print(ks_statistic, p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15401eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Feature Matrix into required form\n",
    "for i in range(N):\n",
    "    #list_features[i] = torch.from_numpy(np.random.rand(6,26)).float()\n",
    "    list_features[i] = torch.from_numpy(features).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8646e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Data Set\n",
    "data = list(zip(list_adj, list_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "feat_dim=10\n",
    "hidden1=64\n",
    "hidden2=16\n",
    "dropout=0.0\n",
    "lr = 0.01\n",
    "n_nodes=5\n",
    "epochs=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baf6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, dropout=0., act=F.relu):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.dropout = dropout\n",
    "        self.act = act\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.weight)\n",
    "        #self.weight=self.weight.float()\n",
    "    \n",
    "    def forward(self, input, adj):\n",
    "        input = F.dropout(input, self.dropout, self.training)\n",
    "        support = torch.mm(input, self.weight)\n",
    "        if not isinstance(adj, torch.sparse.FloatTensor):\n",
    "            raise ValueError(\"adj must be a sparse tensor\")\n",
    "        output = torch.sparse.mm(adj, support)\n",
    "        output = self.act(output)\n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a60b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModelVAE(nn.Module):\n",
    "    def __init__(self, input_feat_dim, hidden_dim1, hidden_dim2, dropout):\n",
    "        super(GCNModelVAE, self).__init__()\n",
    "        self.gc1 = GraphConvolution(feat_dim, hidden1, dropout, act=F.relu)\n",
    "        self.gc2 = GraphConvolution(hidden1, hidden2, dropout, act=lambda x: x)\n",
    "        self.gc3 = GraphConvolution(hidden1, hidden2, dropout, act=lambda x: x)\n",
    "        self.dc = InnerProductDecoder(dropout, act=lambda x: x)\n",
    "\n",
    "    def encode(self, x, adj):\n",
    "        hidden1 = self.gc1(x, adj)\n",
    "        return self.gc2(hidden1, adj), self.gc3(hidden1, adj)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        mu, logvar = self.encode(x, adj)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        #a,b = self.dc(z)\n",
    "        return z,self.dc(z), mu, logvar\n",
    "        #return z, a, b, mu, logvar \n",
    "        #return mu, logvar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec183988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InnerProductDecoder(nn.Module):\n",
    "    \"\"\"Decoder for using inner product for prediction.\"\"\"\n",
    "\n",
    "    def __init__(self, dropout, act=torch.sigmoid):\n",
    "        super(InnerProductDecoder, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = F.dropout(z, self.dropout, training=self.training)\n",
    "        adj = F.sigmoid(torch.mm(z, z.t()))\n",
    "        #m = Dirichlet(torch.tensor(conce))\n",
    "        #adj = m.sample()\n",
    "        #return conce,adj\n",
    "        return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d71aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCNModelVAE(feat_dim, hidden1, hidden2, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a1e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(preds, labels, mu, logvar, n_nodes):\n",
    "    cost = 0.6 * F.binary_cross_entropy_with_logits(preds, labels)\n",
    "    #cost = F.binary_cross_entropy_with_logits(preds, labels)\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    #loss = nn.MSELoss()\n",
    "    #cost = loss(preds,labels)\n",
    "    KLD = -0.5 / n_nodes * torch.mean(torch.sum(\n",
    "        1 + 2 * logvar - mu.pow(2) - logvar.exp().pow(2), 1))\n",
    "    return cost + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827f152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_graph(adj):\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    adj_ = adj + sp.eye(adj.shape[0])\n",
    "    rowsum = np.array(adj_.sum(1))\n",
    "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
    "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt)\n",
    "    # return sparse_to_tuple(adj_normalized)\n",
    "    return sparse_mx_to_torch_sparse_tensor(adj_normalized)\n",
    "    #return adj_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f626a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dab31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_embed = [0 for _ in range(N)]\n",
    "list_mu = [0 for _ in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a696e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "hidden_emb = None\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i in range(N):\n",
    "        t = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Assuming data[i][1] is node features and data[i][0] is the adjacency matrix\n",
    "        node_features = data[i][1]\n",
    "        adj_matrix = data[i][0][0]\n",
    "        \n",
    "        # Preprocess the adjacency matrix to a sparse tensor\n",
    "        adj_normalized = preprocess_graph(adj_matrix)\n",
    "        \n",
    "        # Forward pass\n",
    "        embed, recovered, mu, logvar = model(node_features, adj_normalized)\n",
    "        \n",
    "        # Update lists of embeddings and means\n",
    "        list_mu[i] = mu\n",
    "        list_embed[i] = embed\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_function(preds=recovered, labels=adj_matrix, mu=mu, logvar=logvar, n_nodes=n_nodes)\n",
    "        \n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the total loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    #print(\"Epoch:\", '%04d' % (epoch + 1), \"Average loss=\", \"{:.5f}\".format(total_loss / N))\n",
    "    \n",
    "end_time = time.time()\n",
    "# Calculate the total elapsed time\n",
    "total_running_time_emb = end_time - start_time\n",
    "total_running_time_emb1 = total_running_time_emb/200\n",
    "print(\"Total running time for GVAE:\", total_running_time_emb1, \"seconds\")\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16572d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_graph_embed = [0 for _ in range(N)]\n",
    "for i in range(N):\n",
    "    list_graph_embed[i] = list_embed[i].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20287f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_graph_embed = [0 for _ in range(N)]\n",
    "for i in range(N):\n",
    "    arr_graph_embed[i] = list_graph_embed[i].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f45a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4ad414",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_scores = []\n",
    "for num_clusters in range(2, 13):\n",
    "    km = KMeans(n_clusters=num_clusters, max_iter=2000, init='k-means++')\n",
    "    km.fit(arr_graph_embed)\n",
    "    silhouette_scores.append(silhouette_score(arr_graph_embed, km.labels_))\n",
    "    \n",
    "plt.plot(range(2, 13), silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for Different Numbers of Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6156c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b163ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "sse = []\n",
    "for num_clusters in range(2, 20):\n",
    "    km = KMeans(n_clusters=num_clusters, max_iter=2000, init='k-means++')\n",
    "    km.fit(arr_graph_embed)\n",
    "    sse.append(km.inertia_)\n",
    "\n",
    "plt.plot(range(2, 20), sse, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Within-Cluster Sum of Squares (SSE)')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179239d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "km = KMeans(n_clusters=5, max_iter=2000, init='random')\n",
    "km = km.fit(arr_graph_embed)\n",
    "end_time = time.time()\n",
    "# Calculate the total elapsed time\n",
    "total_running_time_clust = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143def3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "km.cluster_centers_\n",
    "label=km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ec93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc0935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count1 represents the number of times a model is repeated \n",
    "un=np.unique(label)\n",
    "count1=[0 for _ in range(len(un))]\n",
    "# count of unique labels in the cluster labels\n",
    "for i in range(len(un)):\n",
    "    for j in range(N):\n",
    "        if label[j]==i:\n",
    "            count1[i]=count1[i]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a376755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tuple to identify cluster representative\n",
    "def clustering(cluster_index):\n",
    "    j=0\n",
    "    s=[]\n",
    "    for i in range(len(label)):\n",
    "        if label[i]==cluster_index:\n",
    "            lis_c[j]=arr_graph_embed[i]\n",
    "            s.append((cluster_index,j,i))\n",
    "            j+=1\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0796669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clus(cluster_index):\n",
    "    lis_c=[[0]*5 for _ in range(count1[cluster_index])]  # 6 represents Number of clusters\n",
    "    j=0\n",
    "    i=0\n",
    "    #s=[]\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == cluster_index:\n",
    "            lis_c[j]=arr_graph_embed[i]\n",
    "            j+=1\n",
    "    return lis_c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b920244",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis=[0 for _ in range(len(un))]\n",
    "for i in range(len(un)):\n",
    "    lis[i]=clus(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_clustering = [0 for _ in range(len(un))]\n",
    "for i in range(len(un)):\n",
    "    lis_c=[[0]*5 for _ in range(count1[i])]\n",
    "    list_clustering[i] = clustering(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c016907",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Identifying cluster representative\n",
    "def cluster_representative(cluster_index):\n",
    "    Dist_Mat=[[0]*count1[cluster_index] for _ in range(count1[cluster_index])]\n",
    "    ind=0\n",
    "    for i in range(0,count1[cluster_index]):\n",
    "        for j in range(0,count1[cluster_index]):\n",
    "            Dist_Mat[i][j] = math.dist(lis[cluster_index][i],lis[cluster_index][j])\n",
    "    Dist_Mat1=np.array(Dist_Mat) \n",
    "    x=Dist_Mat1.sum(axis=0)\n",
    "    ind = np.where(x == min(x))\n",
    "    s1 = list_clustering[cluster_index][ind[0][0]][2]\n",
    "    return arr_graph_embed[list_clustering[cluster_index][ind[0][0]][2]], s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_rep=[0 for _ in range(len(un))]\n",
    "s1 = [0 for _ in range(len(un))]\n",
    "for i in range(len(un)):\n",
    "    clust_rep[i], s1[i] = cluster_representative(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e2d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums_by_label = {}\n",
    "\n",
    "# Iterate through each label and corresponding partition value\n",
    "for lbl, part in zip(label, partitions):\n",
    "    if lbl not in sums_by_label:\n",
    "        sums_by_label[lbl] = 0  # Initialize the sum for the label if it doesn't exist\n",
    "    sums_by_label[lbl] += part  # Add the partition value to the sum for the label\n",
    "\n",
    "# Print the sums for each label\n",
    "for lbl, total_sum in sums_by_label.items():\n",
    "    print(f\"Sum for label {lbl}: {total_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b27c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_cal(cluster_index):\n",
    "    total_sum = 0\n",
    "\n",
    "    for lbl, part in zip(label, partitions):\n",
    "        if lbl == i:\n",
    "            total_sum += part\n",
    "\n",
    "    return total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ce09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_cal(cluster_index):\n",
    "    total_sum = 0\n",
    "\n",
    "    for lbl, part in zip(label, partitions):\n",
    "        if lbl == cluster_index:\n",
    "            total_sum += part\n",
    "\n",
    "    return total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661ccede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of the time durations of each model\n",
    "time_model = [ 0 for _ in range(len(un))]\n",
    "for i in range(len(un)):\n",
    "    #sum1 = [[0]*count1[i] for _ in range(count1[i])]\n",
    "    time_model[i] = time_cal(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a438a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_m = [0 for _ in range(len(time_model))]\n",
    "\n",
    "for i in range(len(time_model)):\n",
    "    avg_time = time_model[i] / count1[i] if count1[i] != 0 else 0\n",
    "    t_m[i] = math.floor(avg_time\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec68d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each model adjacency matrix and its corresponding time duration\n",
    "rep_time = []\n",
    "#rep_time.append(((list_adj[s1[0]].numpy(),t_m[0]),(list_adj[s1[1]].numpy(),t_m[1])))\n",
    "rep_time.append(((list_adj[s1[0]].numpy(),t_m[0]),(list_adj[s1[1]].numpy(),t_m[1]),(list_adj[s1[2]].numpy(),t_m[2]),(list_adj[s1[3]].numpy(),t_m[3]),(list_adj[s1[4]].numpy(),t_m[4])))\n",
    "#rep_time.append(((list_adj[s1[0]].numpy(),t_m[0]),(list_adj[s1[1]].numpy(),t_m[1]),(list_adj[s1[2]].numpy(),t_m[2]),(list_adj[s1[3]].numpy(),t_m[3]),(list_adj[s1[4]].numpy(),t_m[4]),(list_adj[s1[5]].numpy(),t_m[5]),\n",
    "               # (list_adj[s1[6]].numpy(),t_m[6]),(list_adj[s1[7]].numpy(),t_m[7]),(list_adj[s1[8]].numpy(),t_m[8]),(list_adj[s1[9]].numpy(),t_m[9])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5743cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markov Model\n",
    "def onestep_transition_matrix1(transitions,n):\n",
    "   # n = 5 #number of clusters\n",
    "\n",
    "    M = [[1]*n for _ in range(n)]\n",
    "\n",
    "    for (i,j) in zip(transitions,transitions[1:]):\n",
    "        M[i-1][j-1] += 1\n",
    "\n",
    "    #now convert to probabilities:\n",
    "    for row in M:\n",
    "        s = sum(row)\n",
    "        s\n",
    "        if s > 0:\n",
    "            row[:] = [(f+1)/(s+n) for f in row] #laplace smoothing\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d391ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twostep_transition_matrix(transitions,n): \n",
    "    #n = 5  # number of states\n",
    "    M = [[[0]*n for _ in range(n)] for _ in range(n)]\n",
    "    \n",
    "    for (i, j, k) in zip(transitions, transitions[1:], transitions[2:]): \n",
    "        M[i-1][j-1][k-1] += 1 \n",
    "\n",
    "    # Convert counts to probabilities with Laplace smoothing\n",
    "    for matrix in M:  \n",
    "        for row in matrix:\n",
    "            s = sum(row)\n",
    "            if s > 0:\n",
    "                row[:] = [(f + 1) / (s + n) for f in row]  # laplace smoothing\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72decec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6abca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Transition Matrix\n",
    "htm = np.array(onestep_transition_matrix1(label,len(un)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff036b5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Global Transition Matrix\n",
    "htm = np.array(twostep_transition_matrix(label,len(un)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "    \n",
    "    # Calculate the running time for this repetition\n",
    "repetition_running_time_hiera = end_time - start_time\n",
    "repetition_running_time_hiera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c8553",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_training_time = repetition_running_time_hiera+total_running_time_clust+(total_running_time_emb/100)+repetition_running_time_partition_create+total_running_time_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e0e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_higher = np.unique(label)\n",
    "states = np.unique(df1['Task Domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea38fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_res_num(pred_res):\n",
    "    res_num = [[0] * 1 for _ in range(len(pred_res))]\n",
    "    for i in range(len(pred_res)):\n",
    "        if pred_res[i] == 0:\n",
    "            res_num[i] = [np.random.standard_cauchy(1) * 2.9893542376801 + 51.51438521750882, np.random.normal(89.69712191001122, 1.8488024325537014),np.random.normal(42.31731355271662, 3.1400327494071583),np.random.normal(33.527714137443645, 2.5242247874905877),np.random.normal(13.569423330333947, 4.168251587766369)]\n",
    "        elif pred_res[i] == 1:\n",
    "            res_num[i] = [np.random.standard_cauchy(size=1) * 4.509662660345478 + 36.00421486122699, np.random.normal(87.51321559499601, 2.2413093129569885),np.random.normal(40.21508119726604, 3.206382354655931),np.random.standard_cauchy(1) * 1.5318158079539732+ 31.310652708648206,np.random.normal(9.847255264104716, 1.5022002841723094)]\n",
    "        elif pred_res[i] == 2:\n",
    "            res_num[i] = [np.random.standard_cauchy(size=1) * 1.8027742048610422 + 26.969217374984567, np.random.normal(87.60243106540257, 2.5061420048894583),np.random.normal(40.28278255700421, 3.4983807963924822),np.random.normal(31.92869773202124, 2.7876681456268133),np.random.standard_cauchy(1) * 0.5882536377766454+ 5.013670673760187]\n",
    "        elif pred_res[i] == 3:\n",
    "            res_num[i] = [np.random.normal(40.36470039752409, 5.080138827582591),np.random.normal(89.97972609963598, 1.544912841589661),np.random.normal(43.76704290596112, 3.0172242609405355),np.random.normal(34.720854795085714, 2.4402083661714475),np.random.standard_cauchy(1)* 1.0934495398530535+ 6.426441255901989]\n",
    "        elif pred_res[i] == 4:\n",
    "            res_num[i] = [np.random.normal(37.24384121935113, 5.115999644431855),np.random.normal(86.13647320958988, 1.9829845423315906),np.random.normal(39.08362029960354, 3.433479664822717),np.random.normal(30.97130589815287, 2.738960247710485),np.random.standard_cauchy(1)* 0.9102716413582077+ 5.991651572577391]\n",
    "    return res_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b27d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minute Level\n",
    "running_times=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b78eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import time\n",
    "start_time = time.time()\n",
    "# Define the list of prediction lengths you want to test\n",
    "#prediction_lengths = [12,18,24,30,36,42,48,54,60,66,72,78,84,90,96,98,108,114,120, 132, 144 ]  # Add more lengths as needed\n",
    "#prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "#prediction_lengths = [144, 156, 168, 180, 192, 204, 216, 228, 240, 252, 264, 276]\n",
    "#prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "#prediction_lengths = [2,3,4,5,6,7,8,9,10,11]\n",
    "prediction_lengths = [100]\n",
    "# Initialize lists to store results for different prediction lengths\n",
    "results = []\n",
    "results_mse = []\n",
    "results_rmse = []\n",
    "results_mae = []\n",
    "results_mape = []\n",
    "prev_higher_state1 = label[len(label)-1]  # Replace with your desired initial state\n",
    "prev_higher_state2 = label[len(label)-2]  # Replace with your desired initial state\n",
    "prev_state =  la[len(train_data)-1] # Replace with your desired initial state\n",
    "prev_state1=  la[len(train_data)-2] # Replace with your desired initial state\n",
    "# Define the number of times you want to repeat the experiment\n",
    "num_experiments = 100\n",
    "for prediction_length in prediction_lengths:\n",
    "   # no_predict1 = prediction_length\n",
    "    # Inner loop for repeating the experiment\n",
    "    for _ in range(num_experiments):\n",
    "        no_predict = prediction_length\n",
    "        pred_res = []\n",
    "        while no_predict > 0:\n",
    "            # Predict the next state at the higher level\n",
    "            higher_transition_probs = htm[prev_higher_state2][prev_higher_state1]\n",
    "    \n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(higher_transition_probs) > 0:\n",
    "                higher_transition_probs /= np.sum(higher_transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, assign equal probabilities to all states\n",
    "                higher_transition_probs = np.ones(len(states_higher)) / len(states_higher)\n",
    "    \n",
    "            next_higher_state = np.random.choice(states_higher, p=higher_transition_probs)\n",
    "    \n",
    "            # Identify the model tuple for the selected higher-level state\n",
    "            selected_model = rep_time[0][next_higher_state]\n",
    "    \n",
    "            # Access the adjacency matrix and time duration for the selected model\n",
    "            model_adj_matrix, model_time_duration = selected_model\n",
    "    \n",
    "            # Calculate transition probabilities for the previous two states\n",
    "            transition_probs = model_adj_matrix[prev_state1][prev_state]\n",
    "\n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(transition_probs) > 0:\n",
    "                transition_probs /= np.sum(transition_probs)\n",
    "\n",
    "                # Sample the next state based on transition probabilities\n",
    "                next_state = np.random.choice(states, p=transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, randomly choose the next state\n",
    "                next_state = np.random.choice(states)\n",
    "\n",
    "            # Append the predicted state to the result\n",
    "            pred_res.append(next_state)\n",
    "\n",
    "            # Update the state variables for the next iteration\n",
    "            prev_higher_state2 = prev_higher_state1\n",
    "            prev_higher_state1 = next_higher_state\n",
    "            prev_state1 = prev_state\n",
    "            prev_state = next_state\n",
    "            no_predict -= 1\n",
    "\n",
    "        res_num = generate_res_num(pred_res)\n",
    "        end_time = time.time()\n",
    "    \n",
    "        # Calculate the running time for this repetition\n",
    "        repetition_running_time = end_time - start_time\n",
    "        running_times.append(repetition_running_time)\n",
    "        #Predicted Data\n",
    "        df_pred = pd.DataFrame(res_num, columns=['CPU_util','mem_util','net_in','net_out','disk'])\n",
    "        ori = df_actual[len(train_data):len(train_data)+prediction_length]\n",
    "        norm = MinMaxScaler(feature_range=(0.15,0.20))\n",
    "        df_pred_norm = pd.DataFrame(norm.fit_transform(df_pred), columns=df_pred.columns)\n",
    "        ori_norm = pd.DataFrame(norm.fit_transform(ori), columns=ori.columns)\n",
    "        actual_values = ori_norm[['CPU_util','mem_util','net_in','net_out','disk']]\n",
    "        predicted_values = df_pred_norm\n",
    "        mse_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mse = np.mean(mse_per_variable)\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mae_per_variable = mean_absolute_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mae = np.mean(mae_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mape_per_variable = mean_absolute_percentage_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mape = np.mean(mape_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        rms_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values', squared=False)\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_rmse = np.mean(rms_per_variable)\n",
    "\n",
    "        #'cpu_usage','gpu_wrk_util','avg_mem','avg_gpu_work_mem'\n",
    "\n",
    "        mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk = mse_per_variable\n",
    "        results_mse.append([prediction_length,mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk])\n",
    "\n",
    "        mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk = mae_per_variable\n",
    "        results_mae.append([prediction_length, mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk])\n",
    "\n",
    "        rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk = rms_per_variable\n",
    "        results_rmse.append([prediction_length, rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk])\n",
    "    \n",
    "        mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk = mape_per_variable\n",
    "        results_mape.append([prediction_length,mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk])\n",
    "        results.append([prediction_length, average_mse, average_mae, average_rmse, average_mape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0e85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of running times to a NumPy array\n",
    "running_times = np.array(running_times)\n",
    "\n",
    "# Calculate the average running time\n",
    "average_running_time = np.mean(running_times)\n",
    "print(f\"Average running time for repetitions: {average_running_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_results = pd.DataFrame(results, columns=['Prediction Length','average MSE','average MAE','average RMSE','average MAPE'])\n",
    "results_df_results.to_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\Average_Order_2_Minutes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad7b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\Average_Order_2_Minutes.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter records where 'Hours' < 1\n",
    "#filtered_df = df[df['Hours'] < 24]\n",
    "hours_list = [3,18,20,25,26,45,52,51,50]\n",
    "#hours_list = list(range(2, 20))\n",
    "# Filter records where 'Hours' is in the list\n",
    "filtered_df = df[df['Index'].isin(hours_list)]\n",
    "\n",
    "# Calculate mean and standard error for each column\n",
    "mean_values = filtered_df.mean()\n",
    "std_values = filtered_df.std() / np.sqrt(len(filtered_df))\n",
    "\n",
    "# Create the \"x ± y\" representation for each column\n",
    "result = {}\n",
    "for column in df.columns[2:]:  # Exclude the non-RMSE columns\n",
    "    x = mean_values[column]\n",
    "    y = std_values[column]\n",
    "    result[column] = f\"{x:.4f} ± {y:.6f}\"\n",
    "\n",
    "# Display the \"x ± y\" representation for each column\n",
    "for column, value in result.items():\n",
    "    print(f\"{column}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a4b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hour Level (1-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Define the list of prediction lengths you want to test\n",
    "prediction_lengths = [12,18,24,30,36,42,48,54,60,66,72,78,84,90,96,98,108,114,120, 132, 144 ]  # Add more lengths as needed\n",
    "#prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "#prediction_lengths = [144, 156, 168, 180, 192, 204, 216, 228, 240, 252, 264, 276]\n",
    "#prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "#prediction_lengths = [2,3,4,5,6,7,8,9,10,11]\n",
    "# Initialize lists to store results for different prediction lengths\n",
    "results = []\n",
    "results_mse = []\n",
    "results_rmse = []\n",
    "results_mae = []\n",
    "results_mape = []\n",
    "prev_higher_state1 = label[len(label)-1]  # Replace with your desired initial state\n",
    "prev_higher_state2 = label[len(label)-2]  # Replace with your desired initial state\n",
    "prev_state =  la[len(train_data)-1] # Replace with your desired initial state\n",
    "prev_state1=  la[len(train_data)-2] # Replace with your desired initial state\n",
    "# Define the number of times you want to repeat the experiment\n",
    "num_experiments = 100\n",
    "for prediction_length in prediction_lengths:\n",
    "   # no_predict1 = prediction_length\n",
    "    # Inner loop for repeating the experiment\n",
    "    for _ in range(num_experiments):\n",
    "        no_predict = prediction_length\n",
    "        pred_res = []\n",
    "        while no_predict > 0:\n",
    "            # Predict the next state at the higher level\n",
    "            higher_transition_probs = htm[prev_higher_state2][prev_higher_state1]\n",
    "    \n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(higher_transition_probs) > 0:\n",
    "                higher_transition_probs /= np.sum(higher_transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, assign equal probabilities to all states\n",
    "                higher_transition_probs = np.ones(len(states_higher)) / len(states_higher)\n",
    "    \n",
    "            next_higher_state = np.random.choice(states_higher, p=higher_transition_probs)\n",
    "    \n",
    "            # Identify the model tuple for the selected higher-level state\n",
    "            selected_model = rep_time[0][next_higher_state]\n",
    "    \n",
    "            # Access the adjacency matrix and time duration for the selected model\n",
    "            model_adj_matrix, model_time_duration = selected_model\n",
    "    \n",
    "            # Calculate transition probabilities for the previous two states\n",
    "            transition_probs = model_adj_matrix[prev_state1][prev_state]\n",
    "\n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(transition_probs) > 0:\n",
    "                transition_probs /= np.sum(transition_probs)\n",
    "\n",
    "                # Sample the next state based on transition probabilities\n",
    "                next_state = np.random.choice(states, p=transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, randomly choose the next state\n",
    "                next_state = np.random.choice(states)\n",
    "\n",
    "            # Append the predicted state to the result\n",
    "            pred_res.append(next_state)\n",
    "\n",
    "            # Update the state variables for the next iteration\n",
    "            prev_higher_state2 = prev_higher_state1\n",
    "            prev_higher_state1 = next_higher_state\n",
    "            prev_state1 = prev_state\n",
    "            prev_state = next_state\n",
    "            no_predict -= 1\n",
    "\n",
    "        res_num = generate_res_num(pred_res)\n",
    "        \n",
    "        #Predicted Data\n",
    "        df_pred = pd.DataFrame(res_num, columns=['CPU_util','mem_util','net_in','net_out','disk'])\n",
    "        ori = df_actual[len(train_data):len(train_data)+prediction_length]\n",
    "        norm = MinMaxScaler(feature_range=(0.15,0.20))\n",
    "        df_pred_norm = pd.DataFrame(norm.fit_transform(df_pred), columns=df_pred.columns)\n",
    "        ori_norm = pd.DataFrame(norm.fit_transform(ori), columns=ori.columns)\n",
    "        actual_values = ori_norm[['CPU_util','mem_util','net_in','net_out','disk']]\n",
    "        predicted_values = df_pred_norm\n",
    "        mse_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mse = np.mean(mse_per_variable)\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mae_per_variable = mean_absolute_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mae = np.mean(mae_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mape_per_variable = mean_absolute_percentage_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mape = np.mean(mape_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        rms_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values', squared=False)\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_rmse = np.mean(rms_per_variable)\n",
    "\n",
    "        #'cpu_usage','gpu_wrk_util','avg_mem','avg_gpu_work_mem'\n",
    "\n",
    "        mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk = mse_per_variable\n",
    "        results_mse.append([prediction_length,mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk])\n",
    "\n",
    "        mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk = mae_per_variable\n",
    "        results_mae.append([prediction_length, mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk])\n",
    "\n",
    "        rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk = rms_per_variable\n",
    "        results_rmse.append([prediction_length, rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk])\n",
    "    \n",
    "        mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk = mape_per_variable\n",
    "        results_mape.append([prediction_length,mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk])\n",
    "        results.append([prediction_length, average_mse, average_mae, average_rmse, average_mape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_results = pd.DataFrame(results, columns=['Prediction Length','average MSE','average MAE','average RMSE','average MAPE'])\n",
    "results_df_results.to_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\Average_Order_2_Hours_1_12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fed62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\Average_Order_2_Hours_1_12.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter records where 'Hours' < 1\n",
    "#filtered_df = df[df['Hours'] < 24]\n",
    "hours_list = [3,18,20,25,26,45,52,51,50]\n",
    "#hours_list = list(range(2, 20))\n",
    "# Filter records where 'Hours' is in the list\n",
    "filtered_df = df[df['Index'].isin(hours_list)]\n",
    "\n",
    "# Calculate mean and standard error for each column\n",
    "mean_values = filtered_df.mean()\n",
    "std_values = filtered_df.std() / np.sqrt(len(filtered_df))\n",
    "\n",
    "# Create the \"x ± y\" representation for each column\n",
    "result = {}\n",
    "for column in df.columns[2:]:  # Exclude the non-RMSE columns\n",
    "    x = mean_values[column]\n",
    "    y = std_values[column]\n",
    "    result[column] = f\"{x:.4f} ± {y:.6f}\"\n",
    "\n",
    "# Display the \"x ± y\" representation for each column\n",
    "for column, value in result.items():\n",
    "    print(f\"{column}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0f360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hour Level (13-24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14199b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Define the list of prediction lengths you want to test\n",
    "#prediction_lengths = [12,18,24,30,36,42,48,54,60,66,72,78,84,90,96,98,108,114,120, 132, 144 ]  # Add more lengths as needed\n",
    "#prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "prediction_lengths = [144, 156, 168, 180, 192, 204, 216, 228, 240, 252, 264, 276]\n",
    "#prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "#prediction_lengths = [2,3,4,5,6,7,8,9,10,11]\n",
    "# Initialize lists to store results for different prediction lengths\n",
    "results = []\n",
    "results_mse = []\n",
    "results_rmse = []\n",
    "results_mae = []\n",
    "results_mape = []\n",
    "prev_higher_state1 = label[len(label)-1]  # Replace with your desired initial state\n",
    "prev_higher_state2 = label[len(label)-2]  # Replace with your desired initial state\n",
    "prev_state =  la[len(train_data)-1] # Replace with your desired initial state\n",
    "prev_state1=  la[len(train_data)-2] # Replace with your desired initial state\n",
    "# Define the number of times you want to repeat the experiment\n",
    "num_experiments = 100\n",
    "for prediction_length in prediction_lengths:\n",
    "   # no_predict1 = prediction_length\n",
    "    # Inner loop for repeating the experiment\n",
    "    for _ in range(num_experiments):\n",
    "        no_predict = prediction_length\n",
    "        pred_res = []\n",
    "        while no_predict > 0:\n",
    "            # Predict the next state at the higher level\n",
    "            higher_transition_probs = htm[prev_higher_state2][prev_higher_state1]\n",
    "    \n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(higher_transition_probs) > 0:\n",
    "                higher_transition_probs /= np.sum(higher_transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, assign equal probabilities to all states\n",
    "                higher_transition_probs = np.ones(len(states_higher)) / len(states_higher)\n",
    "    \n",
    "            next_higher_state = np.random.choice(states_higher, p=higher_transition_probs)\n",
    "    \n",
    "            # Identify the model tuple for the selected higher-level state\n",
    "            selected_model = rep_time[0][next_higher_state]\n",
    "    \n",
    "            # Access the adjacency matrix and time duration for the selected model\n",
    "            model_adj_matrix, model_time_duration = selected_model\n",
    "    \n",
    "            # Calculate transition probabilities for the previous two states\n",
    "            transition_probs = model_adj_matrix[prev_state1][prev_state]\n",
    "\n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(transition_probs) > 0:\n",
    "                transition_probs /= np.sum(transition_probs)\n",
    "\n",
    "                # Sample the next state based on transition probabilities\n",
    "                next_state = np.random.choice(states, p=transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, randomly choose the next state\n",
    "                next_state = np.random.choice(states)\n",
    "\n",
    "            # Append the predicted state to the result\n",
    "            pred_res.append(next_state)\n",
    "\n",
    "            # Update the state variables for the next iteration\n",
    "            prev_higher_state2 = prev_higher_state1\n",
    "            prev_higher_state1 = next_higher_state\n",
    "            prev_state1 = prev_state\n",
    "            prev_state = next_state\n",
    "            no_predict -= 1\n",
    "\n",
    "        res_num = generate_res_num(pred_res)\n",
    "        \n",
    "        #Predicted Data\n",
    "        df_pred = pd.DataFrame(res_num, columns=['CPU_util','mem_util','net_in','net_out','disk'])\n",
    "        ori = df_actual[len(train_data):len(train_data)+prediction_length]\n",
    "        norm = MinMaxScaler(feature_range=(0.15,0.20))\n",
    "        df_pred_norm = pd.DataFrame(norm.fit_transform(df_pred), columns=df_pred.columns)\n",
    "        ori_norm = pd.DataFrame(norm.fit_transform(ori), columns=ori.columns)\n",
    "        actual_values = ori_norm[['CPU_util','mem_util','net_in','net_out','disk']]\n",
    "        predicted_values = df_pred_norm\n",
    "        mse_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mse = np.mean(mse_per_variable)\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mae_per_variable = mean_absolute_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mae = np.mean(mae_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mape_per_variable = mean_absolute_percentage_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mape = np.mean(mape_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        rms_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values', squared=False)\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_rmse = np.mean(rms_per_variable)\n",
    "\n",
    "        #'cpu_usage','gpu_wrk_util','avg_mem','avg_gpu_work_mem'\n",
    "\n",
    "        mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk = mse_per_variable\n",
    "        results_mse.append([prediction_length,mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk])\n",
    "\n",
    "        mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk = mae_per_variable\n",
    "        results_mae.append([prediction_length, mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk])\n",
    "\n",
    "        rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk = rms_per_variable\n",
    "        results_rmse.append([prediction_length, rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk])\n",
    "    \n",
    "        mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk = mape_per_variable\n",
    "        results_mape.append([prediction_length,mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk])\n",
    "        results.append([prediction_length, average_mse, average_mae, average_rmse, average_mape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d422a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_results = pd.DataFrame(results, columns=['Prediction Length','average MSE','average MAE','average RMSE','average MAPE'])\n",
    "results_df_results.to_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\Average_Order_2_Hours_13_24.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb62d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\Average_Order_2_Hours_13_24.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter records where 'Hours' < 1\n",
    "#filtered_df = df[df['Hours'] < 24]\n",
    "hours_list = [3,18,20,25,26,45,52,51,50]\n",
    "#hours_list = list(range(2, 20))\n",
    "# Filter records where 'Hours' is in the list\n",
    "filtered_df = df[df['Index'].isin(hours_list)]\n",
    "\n",
    "# Calculate mean and standard error for each column\n",
    "mean_values = filtered_df.mean()\n",
    "std_values = filtered_df.std() / np.sqrt(len(filtered_df))\n",
    "\n",
    "# Create the \"x ± y\" representation for each column\n",
    "result = {}\n",
    "for column in df.columns[2:]:  # Exclude the non-RMSE columns\n",
    "    x = mean_values[column]\n",
    "    y = std_values[column]\n",
    "    result[column] = f\"{x:.4f} ± {y:.6f}\"\n",
    "\n",
    "# Display the \"x ± y\" representation for each column\n",
    "for column, value in result.items():\n",
    "    print(f\"{column}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef4725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8063503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Define the list of prediction lengths you want to test\n",
    "#prediction_lengths = [12,18,24,30,36,42,48,54,60,66,72,78,84,90,96,98,108,114,120, 132, 144 ]  # Add more lengths as needed\n",
    "#prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "#prediction_lengths = [144, 156, 168, 180, 192, 204, 216, 228, 240, 252, 264, 276]\n",
    "prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "#prediction_lengths = [2,3,4,5,6,7,8,9,10,11]\n",
    "# Initialize lists to store results for different prediction lengths\n",
    "results = []\n",
    "results_mse = []\n",
    "results_rmse = []\n",
    "results_mae = []\n",
    "results_mape = []\n",
    "prev_higher_state1 = label[len(label)-1]  # Replace with your desired initial state\n",
    "prev_higher_state2 = label[len(label)-2]  # Replace with your desired initial state\n",
    "prev_state =  la[len(train_data)-1] # Replace with your desired initial state\n",
    "prev_state1=  la[len(train_data)-2] # Replace with your desired initial state\n",
    "# Define the number of times you want to repeat the experiment\n",
    "num_experiments = 100\n",
    "for prediction_length in prediction_lengths:\n",
    "   # no_predict1 = prediction_length\n",
    "    # Inner loop for repeating the experiment\n",
    "    for _ in range(num_experiments):\n",
    "        no_predict = prediction_length\n",
    "        pred_res = []\n",
    "        while no_predict > 0:\n",
    "            # Predict the next state at the higher level\n",
    "            higher_transition_probs = htm[prev_higher_state2][prev_higher_state1]\n",
    "    \n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(higher_transition_probs) > 0:\n",
    "                higher_transition_probs /= np.sum(higher_transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, assign equal probabilities to all states\n",
    "                higher_transition_probs = np.ones(len(states_higher)) / len(states_higher)\n",
    "    \n",
    "            next_higher_state = np.random.choice(states_higher, p=higher_transition_probs)\n",
    "    \n",
    "            # Identify the model tuple for the selected higher-level state\n",
    "            selected_model = rep_time[0][next_higher_state]\n",
    "    \n",
    "            # Access the adjacency matrix and time duration for the selected model\n",
    "            model_adj_matrix, model_time_duration = selected_model\n",
    "    \n",
    "            # Calculate transition probabilities for the previous two states\n",
    "            transition_probs = model_adj_matrix[prev_state1][prev_state]\n",
    "\n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(transition_probs) > 0:\n",
    "                transition_probs /= np.sum(transition_probs)\n",
    "\n",
    "                # Sample the next state based on transition probabilities\n",
    "                next_state = np.random.choice(states, p=transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, randomly choose the next state\n",
    "                next_state = np.random.choice(states)\n",
    "\n",
    "            # Append the predicted state to the result\n",
    "            pred_res.append(next_state)\n",
    "\n",
    "            # Update the state variables for the next iteration\n",
    "            prev_higher_state2 = prev_higher_state1\n",
    "            prev_higher_state1 = next_higher_state\n",
    "            prev_state1 = prev_state\n",
    "            prev_state = next_state\n",
    "            no_predict -= 1\n",
    "\n",
    "        res_num = generate_res_num(pred_res)\n",
    "        \n",
    "        #Predicted Data\n",
    "        df_pred = pd.DataFrame(res_num, columns=['CPU_util','mem_util','net_in','net_out','disk'])\n",
    "        ori = df_actual[len(train_data):len(train_data)+prediction_length]\n",
    "        norm = MinMaxScaler(feature_range=(0.15,0.20))\n",
    "        df_pred_norm = pd.DataFrame(norm.fit_transform(df_pred), columns=df_pred.columns)\n",
    "        ori_norm = pd.DataFrame(norm.fit_transform(ori), columns=ori.columns)\n",
    "        actual_values = ori_norm[['CPU_util','mem_util','net_in','net_out','disk']]\n",
    "        predicted_values = df_pred_norm\n",
    "        mse_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mse = np.mean(mse_per_variable)\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mae_per_variable = mean_absolute_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mae = np.mean(mae_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mape_per_variable = mean_absolute_percentage_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mape = np.mean(mape_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        rms_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values', squared=False)\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_rmse = np.mean(rms_per_variable)\n",
    "\n",
    "        #'cpu_usage','gpu_wrk_util','avg_mem','avg_gpu_work_mem'\n",
    "\n",
    "        mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk = mse_per_variable\n",
    "        results_mse.append([prediction_length,mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk])\n",
    "\n",
    "        mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk = mae_per_variable\n",
    "        results_mae.append([prediction_length, mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk])\n",
    "\n",
    "        rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk = rms_per_variable\n",
    "        results_rmse.append([prediction_length, rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk])\n",
    "    \n",
    "        mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk = mape_per_variable\n",
    "        results_mape.append([prediction_length,mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk])\n",
    "        results.append([prediction_length, average_mse, average_mae, average_rmse, average_mape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058a82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_results = pd.DataFrame(results, columns=['Prediction Length','average MSE','average MAE','average RMSE','average MAPE'])\n",
    "results_df_results.to_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\Average_Order_2_Day.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7f932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\Average_Order_2_Day.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter records where 'Hours' < 1\n",
    "#filtered_df = df[df['Hours'] < 24]\n",
    "hours_list = [3,18,20,25,26,45,52,51,50]\n",
    "#hours_list = list(range(2, 20))\n",
    "# Filter records where 'Hours' is in the list\n",
    "filtered_df = df[df['Index'].isin(hours_list)]\n",
    "\n",
    "# Calculate mean and standard error for each column\n",
    "mean_values = filtered_df.mean()\n",
    "std_values = filtered_df.std() / np.sqrt(len(filtered_df))\n",
    "\n",
    "# Create the \"x ± y\" representation for each column\n",
    "result = {}\n",
    "for column in df.columns[2:]:  # Exclude the non-RMSE columns\n",
    "    x = mean_values[column]\n",
    "    y = std_values[column]\n",
    "    result[column] = f\"{x:.4f} ± {y:.6f}\"\n",
    "\n",
    "# Display the \"x ± y\" representation for each column\n",
    "for column, value in result.items():\n",
    "    print(f\"{column}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6306508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce28ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Wise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606df550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU Utilization (Minute Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9385bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Define the list of prediction lengths you want to test\n",
    "#prediction_lengths = [12,18,24,30,36,42,48,54,60,66,72,78,84,90,96,98,108,114,120, 132, 144 ]  # Add more lengths as needed\n",
    "#prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "#prediction_lengths = [144, 156, 168, 180, 192, 204, 216, 228, 240, 252, 264, 276]\n",
    "#prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "prediction_lengths = [2,3,4,5,6,7,8,9,10,11]\n",
    "# Initialize lists to store results for different prediction lengths\n",
    "results = []\n",
    "results_mse = []\n",
    "results_rmse = []\n",
    "results_mae = []\n",
    "results_mape = []\n",
    "results_metrics_cpu = []\n",
    "results_metrics_canonical_mem = []\n",
    "results_metrics_assigned_mem = []\n",
    "results_metrics_cache_mem =[]\n",
    "results_metrics_disk = []\n",
    "prev_higher_state1 = label[len(label)-1]  # Replace with your desired initial state\n",
    "prev_higher_state2 = label[len(label)-2]  # Replace with your desired initial state\n",
    "prev_state =  la[len(train_data)-1] # Replace with your desired initial state\n",
    "prev_state1=  la[len(train_data)-2] # Replace with your desired initial state\n",
    "# Define the number of times you want to repeat the experiment\n",
    "num_experiments = 50\n",
    "for prediction_length in prediction_lengths:\n",
    "   # no_predict1 = prediction_length\n",
    "    # Inner loop for repeating the experiment\n",
    "    for _ in range(num_experiments):\n",
    "        no_predict = prediction_length\n",
    "        pred_res = []\n",
    "        while no_predict > 0:\n",
    "            # Predict the next state at the higher level\n",
    "            higher_transition_probs = htm[prev_higher_state2][prev_higher_state1]\n",
    "    \n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(higher_transition_probs) > 0:\n",
    "                higher_transition_probs /= np.sum(higher_transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, assign equal probabilities to all states\n",
    "                higher_transition_probs = np.ones(len(states_higher)) / len(states_higher)\n",
    "    \n",
    "            next_higher_state = np.random.choice(states_higher, p=higher_transition_probs)\n",
    "    \n",
    "            # Identify the model tuple for the selected higher-level state\n",
    "            selected_model = rep_time[0][next_higher_state]\n",
    "    \n",
    "            # Access the adjacency matrix and time duration for the selected model\n",
    "            model_adj_matrix, model_time_duration = selected_model\n",
    "    \n",
    "            # Calculate transition probabilities for the previous two states\n",
    "            transition_probs = model_adj_matrix[prev_state1][prev_state]\n",
    "\n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(transition_probs) > 0:\n",
    "                transition_probs /= np.sum(transition_probs)\n",
    "\n",
    "                # Sample the next state based on transition probabilities\n",
    "                next_state = np.random.choice(states, p=transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, randomly choose the next state\n",
    "                next_state = np.random.choice(states)\n",
    "\n",
    "            # Append the predicted state to the result\n",
    "            pred_res.append(next_state)\n",
    "\n",
    "            # Update the state variables for the next iteration\n",
    "            prev_higher_state2 = prev_higher_state1\n",
    "            prev_higher_state1 = next_higher_state\n",
    "            prev_state1 = prev_state\n",
    "            prev_state = next_state\n",
    "            no_predict -= 1\n",
    "\n",
    "        res_num = generate_res_num(pred_res)\n",
    "        \n",
    "        #Predicted Data\n",
    "        df_pred = pd.DataFrame(res_num, columns=['CPU_util','mem_util','net_in','net_out','disk'])\n",
    "        ori = df_actual[len(train_data):len(train_data)+prediction_length]\n",
    "        norm = MinMaxScaler(feature_range=(0.15,0.20))\n",
    "        df_pred_norm = pd.DataFrame(norm.fit_transform(df_pred), columns=df_pred.columns)\n",
    "        ori_norm = pd.DataFrame(norm.fit_transform(ori), columns=ori.columns)\n",
    "        actual_values = ori_norm[['CPU_util','mem_util','net_in','net_out','disk']]\n",
    "        predicted_values = df_pred_norm\n",
    "        mse_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mse = np.mean(mse_per_variable)\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mae_per_variable = mean_absolute_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mae = np.mean(mae_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mape_per_variable = mean_absolute_percentage_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mape = np.mean(mape_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        rms_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values', squared=False)\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_rmse = np.mean(rms_per_variable)\n",
    "\n",
    "        #'cpu_usage','gpu_wrk_util','avg_mem','avg_gpu_work_mem'\n",
    "\n",
    "        mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk = mse_per_variable\n",
    "        results_mse.append([prediction_length,mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk])\n",
    "\n",
    "        mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk = mae_per_variable\n",
    "        results_mae.append([prediction_length, mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk])\n",
    "\n",
    "        rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk = rms_per_variable\n",
    "        results_rmse.append([prediction_length, rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk])\n",
    "    \n",
    "        mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk = mape_per_variable\n",
    "        results_mape.append([prediction_length,mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk])\n",
    "        results.append([prediction_length, average_mse, average_mae, average_rmse, average_mape])\n",
    "        \n",
    "        results_metrics_cpu.append([prediction_length, mse_cpu_util,mae_cpu_util, rmse_cpu_util,mape_cpu_util])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_cpu_metrics = pd.DataFrame(results_metrics_cpu, columns=['Prediction Length','MSE_mean_cpu_usage','RMSE_mean_cpu_usage','MAE_mean_cpu_usage','MAPE_mean_cpu_usage'])\n",
    "results_df_cpu_metrics.to_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\CPU_Metrics_SMPM_Order2_Minutes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758dfb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\CPU_Metrics_SMPM_Order2_Minutes.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter records where 'Hours' < 1\n",
    "#filtered_df = df[df['Hours'] < 24]\n",
    "\n",
    "hours_list = list(range(37,60))\n",
    "#hours_list = [288,304,313,314,327,337,334]\n",
    "\n",
    "# Filter records where 'Hours' is in the list\n",
    "filtered_df = df[df['Index'].isin(hours_list)]\n",
    "\n",
    "# Calculate mean and standard error for each column\n",
    "mean_values = filtered_df.mean()\n",
    "std_values = filtered_df.std() / np.sqrt(len(filtered_df))\n",
    "\n",
    "# Create the \"x ± y\" representation for each column\n",
    "result = {}\n",
    "for column in df.columns[2:]:  # Exclude the non-RMSE columns\n",
    "    x = mean_values[column]\n",
    "    y = std_values[column]\n",
    "    result[column] = f\"{x:.4f} ± {y:.6f}\"\n",
    "\n",
    "# Display the \"x ± y\" representation for each column\n",
    "for column, value in result.items():\n",
    "    print(f\"{column}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1171977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Define the list of prediction lengths you want to test\n",
    "prediction_lengths = [12,18,24,30,36,42,48,54,60,66,72,78,84,90,96,98,108,114,120, 132, 144 ]  # Add more lengths as needed\n",
    "#prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "#prediction_lengths = [144, 156, 168, 180, 192, 204, 216, 228, 240, 252, 264, 276]\n",
    "#prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "#prediction_lengths = [2,3,4,5,6,7,8,9,10,11]\n",
    "# Initialize lists to store results for different prediction lengths\n",
    "results = []\n",
    "results_mse = []\n",
    "results_rmse = []\n",
    "results_mae = []\n",
    "results_mape = []\n",
    "results_metrics_cpu = []\n",
    "results_metrics_canonical_mem = []\n",
    "results_metrics_assigned_mem = []\n",
    "results_metrics_cache_mem =[]\n",
    "results_metrics_disk = []\n",
    "prev_higher_state1 = label[len(label)-1]  # Replace with your desired initial state\n",
    "prev_higher_state2 = label[len(label)-2]  # Replace with your desired initial state\n",
    "prev_state =  la[len(train_data)-1] # Replace with your desired initial state\n",
    "prev_state1=  la[len(train_data)-2] # Replace with your desired initial state\n",
    "# Define the number of times you want to repeat the experiment\n",
    "num_experiments = 50\n",
    "for prediction_length in prediction_lengths:\n",
    "   # no_predict1 = prediction_length\n",
    "    # Inner loop for repeating the experiment\n",
    "    for _ in range(num_experiments):\n",
    "        no_predict = prediction_length\n",
    "        pred_res = []\n",
    "        while no_predict > 0:\n",
    "            # Predict the next state at the higher level\n",
    "            higher_transition_probs = htm[prev_higher_state2][prev_higher_state1]\n",
    "    \n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(higher_transition_probs) > 0:\n",
    "                higher_transition_probs /= np.sum(higher_transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, assign equal probabilities to all states\n",
    "                higher_transition_probs = np.ones(len(states_higher)) / len(states_higher)\n",
    "    \n",
    "            next_higher_state = np.random.choice(states_higher, p=higher_transition_probs)\n",
    "    \n",
    "            # Identify the model tuple for the selected higher-level state\n",
    "            selected_model = rep_time[0][next_higher_state]\n",
    "    \n",
    "            # Access the adjacency matrix and time duration for the selected model\n",
    "            model_adj_matrix, model_time_duration = selected_model\n",
    "    \n",
    "            # Calculate transition probabilities for the previous two states\n",
    "            transition_probs = model_adj_matrix[prev_state1][prev_state]\n",
    "\n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(transition_probs) > 0:\n",
    "                transition_probs /= np.sum(transition_probs)\n",
    "\n",
    "                # Sample the next state based on transition probabilities\n",
    "                next_state = np.random.choice(states, p=transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, randomly choose the next state\n",
    "                next_state = np.random.choice(states)\n",
    "\n",
    "            # Append the predicted state to the result\n",
    "            pred_res.append(next_state)\n",
    "\n",
    "            # Update the state variables for the next iteration\n",
    "            prev_higher_state2 = prev_higher_state1\n",
    "            prev_higher_state1 = next_higher_state\n",
    "            prev_state1 = prev_state\n",
    "            prev_state = next_state\n",
    "            no_predict -= 1\n",
    "\n",
    "        res_num = generate_res_num(pred_res)\n",
    "        \n",
    "        #Predicted Data\n",
    "        df_pred = pd.DataFrame(res_num, columns=['CPU_util','mem_util','net_in','net_out','disk'])\n",
    "        ori = df_actual[len(train_data):len(train_data)+prediction_length]\n",
    "        norm = MinMaxScaler(feature_range=(0.15,0.20))\n",
    "        df_pred_norm = pd.DataFrame(norm.fit_transform(df_pred), columns=df_pred.columns)\n",
    "        ori_norm = pd.DataFrame(norm.fit_transform(ori), columns=ori.columns)\n",
    "        actual_values = ori_norm[['CPU_util','mem_util','net_in','net_out','disk']]\n",
    "        predicted_values = df_pred_norm\n",
    "        mse_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mse = np.mean(mse_per_variable)\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mae_per_variable = mean_absolute_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mae = np.mean(mae_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mape_per_variable = mean_absolute_percentage_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mape = np.mean(mape_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        rms_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values', squared=False)\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_rmse = np.mean(rms_per_variable)\n",
    "\n",
    "        #'cpu_usage','gpu_wrk_util','avg_mem','avg_gpu_work_mem'\n",
    "\n",
    "        mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk = mse_per_variable\n",
    "        results_mse.append([prediction_length,mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk])\n",
    "\n",
    "        mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk = mae_per_variable\n",
    "        results_mae.append([prediction_length, mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk])\n",
    "\n",
    "        rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk = rms_per_variable\n",
    "        results_rmse.append([prediction_length, rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk])\n",
    "    \n",
    "        mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk = mape_per_variable\n",
    "        results_mape.append([prediction_length,mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk])\n",
    "        results.append([prediction_length, average_mse, average_mae, average_rmse, average_mape])\n",
    "        \n",
    "        results_metrics_cpu.append([prediction_length, mse_cpu_util,mae_cpu_util, rmse_cpu_util,mape_cpu_util])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab43f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_cpu_metrics = pd.DataFrame(results_metrics_cpu, columns=['Prediction Length','MSE_mean_cpu_usage','RMSE_mean_cpu_usage','MAE_mean_cpu_usage','MAPE_mean_cpu_usage'])\n",
    "results_df_cpu_metrics.to_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\CPU_Metrics_SMPM_Order2_Hours_1_12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\CPU_Metrics_SMPM_Order2_Hours_1_12.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter records where 'Hours' < 1\n",
    "#filtered_df = df[df['Hours'] < 24]\n",
    "\n",
    "hours_list = list(range(37,60))\n",
    "#hours_list = [288,304,313,314,327,337,334]\n",
    "\n",
    "# Filter records where 'Hours' is in the list\n",
    "filtered_df = df[df['Index'].isin(hours_list)]\n",
    "\n",
    "# Calculate mean and standard error for each column\n",
    "mean_values = filtered_df.mean()\n",
    "std_values = filtered_df.std() / np.sqrt(len(filtered_df))\n",
    "\n",
    "# Create the \"x ± y\" representation for each column\n",
    "result = {}\n",
    "for column in df.columns[2:]:  # Exclude the non-RMSE columns\n",
    "    x = mean_values[column]\n",
    "    y = std_values[column]\n",
    "    result[column] = f\"{x:.4f} ± {y:.6f}\"\n",
    "\n",
    "# Display the \"x ± y\" representation for each column\n",
    "for column, value in result.items():\n",
    "    print(f\"{column}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da0b6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d7072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Define the list of prediction lengths you want to test\n",
    "#prediction_lengths = [12,18,24,30,36,42,48,54,60,66,72,78,84,90,96,98,108,114,120, 132, 144 ]  # Add more lengths as needed\n",
    "#prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "prediction_lengths = [144, 156, 168, 180, 192, 204, 216, 228, 240, 252, 264, 276]\n",
    "#prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "#prediction_lengths = [2,3,4,5,6,7,8,9,10,11]\n",
    "# Initialize lists to store results for different prediction lengths\n",
    "results = []\n",
    "results_mse = []\n",
    "results_rmse = []\n",
    "results_mae = []\n",
    "results_mape = []\n",
    "results_metrics_cpu = []\n",
    "results_metrics_canonical_mem = []\n",
    "results_metrics_assigned_mem = []\n",
    "results_metrics_cache_mem =[]\n",
    "results_metrics_disk = []\n",
    "prev_higher_state1 = label[len(label)-1]  # Replace with your desired initial state\n",
    "prev_higher_state2 = label[len(label)-2]  # Replace with your desired initial state\n",
    "prev_state =  la[len(train_data)-1] # Replace with your desired initial state\n",
    "prev_state1=  la[len(train_data)-2] # Replace with your desired initial state\n",
    "# Define the number of times you want to repeat the experiment\n",
    "num_experiments = 50\n",
    "for prediction_length in prediction_lengths:\n",
    "   # no_predict1 = prediction_length\n",
    "    # Inner loop for repeating the experiment\n",
    "    for _ in range(num_experiments):\n",
    "        no_predict = prediction_length\n",
    "        pred_res = []\n",
    "        while no_predict > 0:\n",
    "            # Predict the next state at the higher level\n",
    "            higher_transition_probs = htm[prev_higher_state2][prev_higher_state1]\n",
    "    \n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(higher_transition_probs) > 0:\n",
    "                higher_transition_probs /= np.sum(higher_transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, assign equal probabilities to all states\n",
    "                higher_transition_probs = np.ones(len(states_higher)) / len(states_higher)\n",
    "    \n",
    "            next_higher_state = np.random.choice(states_higher, p=higher_transition_probs)\n",
    "    \n",
    "            # Identify the model tuple for the selected higher-level state\n",
    "            selected_model = rep_time[0][next_higher_state]\n",
    "    \n",
    "            # Access the adjacency matrix and time duration for the selected model\n",
    "            model_adj_matrix, model_time_duration = selected_model\n",
    "    \n",
    "            # Calculate transition probabilities for the previous two states\n",
    "            transition_probs = model_adj_matrix[prev_state1][prev_state]\n",
    "\n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(transition_probs) > 0:\n",
    "                transition_probs /= np.sum(transition_probs)\n",
    "\n",
    "                # Sample the next state based on transition probabilities\n",
    "                next_state = np.random.choice(states, p=transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, randomly choose the next state\n",
    "                next_state = np.random.choice(states)\n",
    "\n",
    "            # Append the predicted state to the result\n",
    "            pred_res.append(next_state)\n",
    "\n",
    "            # Update the state variables for the next iteration\n",
    "            prev_higher_state2 = prev_higher_state1\n",
    "            prev_higher_state1 = next_higher_state\n",
    "            prev_state1 = prev_state\n",
    "            prev_state = next_state\n",
    "            no_predict -= 1\n",
    "\n",
    "        res_num = generate_res_num(pred_res)\n",
    "        \n",
    "        #Predicted Data\n",
    "        df_pred = pd.DataFrame(res_num, columns=['CPU_util','mem_util','net_in','net_out','disk'])\n",
    "        ori = df_actual[len(train_data):len(train_data)+prediction_length]\n",
    "        norm = MinMaxScaler(feature_range=(0.15,0.20))\n",
    "        df_pred_norm = pd.DataFrame(norm.fit_transform(df_pred), columns=df_pred.columns)\n",
    "        ori_norm = pd.DataFrame(norm.fit_transform(ori), columns=ori.columns)\n",
    "        actual_values = ori_norm[['CPU_util','mem_util','net_in','net_out','disk']]\n",
    "        predicted_values = df_pred_norm\n",
    "        mse_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mse = np.mean(mse_per_variable)\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mae_per_variable = mean_absolute_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mae = np.mean(mae_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mape_per_variable = mean_absolute_percentage_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mape = np.mean(mape_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        rms_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values', squared=False)\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_rmse = np.mean(rms_per_variable)\n",
    "\n",
    "        #'cpu_usage','gpu_wrk_util','avg_mem','avg_gpu_work_mem'\n",
    "\n",
    "        mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk = mse_per_variable\n",
    "        results_mse.append([prediction_length,mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk])\n",
    "\n",
    "        mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk = mae_per_variable\n",
    "        results_mae.append([prediction_length, mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk])\n",
    "\n",
    "        rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk = rms_per_variable\n",
    "        results_rmse.append([prediction_length, rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk])\n",
    "    \n",
    "        mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk = mape_per_variable\n",
    "        results_mape.append([prediction_length,mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk])\n",
    "        results.append([prediction_length, average_mse, average_mae, average_rmse, average_mape])\n",
    "        \n",
    "        results_metrics_cpu.append([prediction_length, mse_cpu_util,mae_cpu_util, rmse_cpu_util,mape_cpu_util])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f1b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_cpu_metrics = pd.DataFrame(results_metrics_cpu, columns=['Prediction Length','MSE_mean_cpu_usage','RMSE_mean_cpu_usage','MAE_mean_cpu_usage','MAPE_mean_cpu_usage'])\n",
    "results_df_cpu_metrics.to_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\CPU_Metrics_SMPM_Order2_Hours_13_24.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17754c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\CPU_Metrics_SMPM_Order2_Hours_13_24.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter records where 'Hours' < 1\n",
    "#filtered_df = df[df['Hours'] < 24]\n",
    "\n",
    "hours_list = list(range(37,60))\n",
    "#hours_list = [288,304,313,314,327,337,334]\n",
    "\n",
    "# Filter records where 'Hours' is in the list\n",
    "filtered_df = df[df['Index'].isin(hours_list)]\n",
    "\n",
    "# Calculate mean and standard error for each column\n",
    "mean_values = filtered_df.mean()\n",
    "std_values = filtered_df.std() / np.sqrt(len(filtered_df))\n",
    "\n",
    "# Create the \"x ± y\" representation for each column\n",
    "result = {}\n",
    "for column in df.columns[2:]:  # Exclude the non-RMSE columns\n",
    "    x = mean_values[column]\n",
    "    y = std_values[column]\n",
    "    result[column] = f\"{x:.4f} ± {y:.6f}\"\n",
    "\n",
    "# Display the \"x ± y\" representation for each column\n",
    "for column, value in result.items():\n",
    "    print(f\"{column}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24c32a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458eebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Define the list of prediction lengths you want to test\n",
    "#prediction_lengths = [12,18,24,30,36,42,48,54,60,66,72,78,84,90,96,98,108,114,120, 132, 144 ]  # Add more lengths as needed\n",
    "prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "#prediction_lengths = [144, 156, 168, 180, 192, 204, 216, 228, 240, 252, 264, 276]\n",
    "#prediction_lengths = [288, 432, 576, 720, 864, 1008, 1152]\n",
    "#prediction_lengths = [2,3,4,5,6,7,8,9,10,11]\n",
    "# Initialize lists to store results for different prediction lengths\n",
    "results = []\n",
    "results_mse = []\n",
    "results_rmse = []\n",
    "results_mae = []\n",
    "results_mape = []\n",
    "results_metrics_cpu = []\n",
    "results_metrics_canonical_mem = []\n",
    "results_metrics_assigned_mem = []\n",
    "results_metrics_cache_mem =[]\n",
    "results_metrics_disk = []\n",
    "prev_higher_state1 = label[len(label)-1]  # Replace with your desired initial state\n",
    "prev_higher_state2 = label[len(label)-2]  # Replace with your desired initial state\n",
    "prev_state =  la[len(train_data)-1] # Replace with your desired initial state\n",
    "prev_state1=  la[len(train_data)-2] # Replace with your desired initial state\n",
    "# Define the number of times you want to repeat the experiment\n",
    "num_experiments = 50\n",
    "for prediction_length in prediction_lengths:\n",
    "   # no_predict1 = prediction_length\n",
    "    # Inner loop for repeating the experiment\n",
    "    for _ in range(num_experiments):\n",
    "        no_predict = prediction_length\n",
    "        pred_res = []\n",
    "        while no_predict > 0:\n",
    "            # Predict the next state at the higher level\n",
    "            higher_transition_probs = htm[prev_higher_state2][prev_higher_state1]\n",
    "    \n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(higher_transition_probs) > 0:\n",
    "                higher_transition_probs /= np.sum(higher_transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, assign equal probabilities to all states\n",
    "                higher_transition_probs = np.ones(len(states_higher)) / len(states_higher)\n",
    "    \n",
    "            next_higher_state = np.random.choice(states_higher, p=higher_transition_probs)\n",
    "    \n",
    "            # Identify the model tuple for the selected higher-level state\n",
    "            selected_model = rep_time[0][next_higher_state]\n",
    "    \n",
    "            # Access the adjacency matrix and time duration for the selected model\n",
    "            model_adj_matrix, model_time_duration = selected_model\n",
    "    \n",
    "            # Calculate transition probabilities for the previous two states\n",
    "            transition_probs = model_adj_matrix[prev_state1][prev_state]\n",
    "\n",
    "            # Normalize transition probabilities if the sum is not zero\n",
    "            if np.sum(transition_probs) > 0:\n",
    "                transition_probs /= np.sum(transition_probs)\n",
    "\n",
    "                # Sample the next state based on transition probabilities\n",
    "                next_state = np.random.choice(states, p=transition_probs)\n",
    "            else:\n",
    "                # If sum is close to zero, randomly choose the next state\n",
    "                next_state = np.random.choice(states)\n",
    "\n",
    "            # Append the predicted state to the result\n",
    "            pred_res.append(next_state)\n",
    "\n",
    "            # Update the state variables for the next iteration\n",
    "            prev_higher_state2 = prev_higher_state1\n",
    "            prev_higher_state1 = next_higher_state\n",
    "            prev_state1 = prev_state\n",
    "            prev_state = next_state\n",
    "            no_predict -= 1\n",
    "\n",
    "        res_num = generate_res_num(pred_res)\n",
    "        \n",
    "        #Predicted Data\n",
    "        df_pred = pd.DataFrame(res_num, columns=['CPU_util','mem_util','net_in','net_out','disk'])\n",
    "        ori = df_actual[len(train_data):len(train_data)+prediction_length]\n",
    "        norm = MinMaxScaler(feature_range=(0.15,0.20))\n",
    "        df_pred_norm = pd.DataFrame(norm.fit_transform(df_pred), columns=df_pred.columns)\n",
    "        ori_norm = pd.DataFrame(norm.fit_transform(ori), columns=ori.columns)\n",
    "        actual_values = ori_norm[['CPU_util','mem_util','net_in','net_out','disk']]\n",
    "        predicted_values = df_pred_norm\n",
    "        mse_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mse = np.mean(mse_per_variable)\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mae_per_variable = mean_absolute_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mae = np.mean(mae_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        mape_per_variable = mean_absolute_percentage_error(actual_values, predicted_values, multioutput='raw_values')\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_mape = np.mean(mape_per_variable)\n",
    "\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) for each variable\n",
    "        rms_per_variable = mean_squared_error(actual_values, predicted_values, multioutput='raw_values', squared=False)\n",
    "\n",
    "        # Calculate the average Mean Squared Error\n",
    "        average_rmse = np.mean(rms_per_variable)\n",
    "\n",
    "        #'cpu_usage','gpu_wrk_util','avg_mem','avg_gpu_work_mem'\n",
    "\n",
    "        mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk = mse_per_variable\n",
    "        results_mse.append([prediction_length,mse_cpu_util, mse_mem_util, mse_net_in, mse_net_out, mse_disk])\n",
    "\n",
    "        mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk = mae_per_variable\n",
    "        results_mae.append([prediction_length, mae_cpu_util, mae_mem_util, mae_net_in, mae_net_out, mae_disk])\n",
    "\n",
    "        rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk = rms_per_variable\n",
    "        results_rmse.append([prediction_length, rmse_cpu_util, rmse_mem_util, rmse_net_in, rmse_net_out, rmse_disk])\n",
    "    \n",
    "        mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk = mape_per_variable\n",
    "        results_mape.append([prediction_length,mape_cpu_util, mape_mem_util, mape_net_in, mape_net_out, mape_disk])\n",
    "        results.append([prediction_length, average_mse, average_mae, average_rmse, average_mape])\n",
    "        \n",
    "        results_metrics_cpu.append([prediction_length, mse_cpu_util,mae_cpu_util, rmse_cpu_util,mape_cpu_util])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2df856",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_cpu_metrics = pd.DataFrame(results_metrics_cpu, columns=['Prediction Length','MSE_mean_cpu_usage','RMSE_mean_cpu_usage','MAE_mean_cpu_usage','MAPE_mean_cpu_usage'])\n",
    "results_df_cpu_metrics.to_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\CPU_Metrics_SMPM_Order2_Day.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0746c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('F:\\\\TCC_revision\\\\Feature_Wise_Results\\\\Alibaba 2018\\\\CPU_Metrics_SMPM_Order2_Day.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter records where 'Hours' < 1\n",
    "#filtered_df = df[df['Hours'] < 24]\n",
    "\n",
    "hours_list = list(range(37,60))\n",
    "#hours_list = [288,304,313,314,327,337,334]\n",
    "\n",
    "# Filter records where 'Hours' is in the list\n",
    "filtered_df = df[df['Index'].isin(hours_list)]\n",
    "\n",
    "# Calculate mean and standard error for each column\n",
    "mean_values = filtered_df.mean()\n",
    "std_values = filtered_df.std() / np.sqrt(len(filtered_df))\n",
    "\n",
    "# Create the \"x ± y\" representation for each column\n",
    "result = {}\n",
    "for column in df.columns[2:]:  # Exclude the non-RMSE columns\n",
    "    x = mean_values[column]\n",
    "    y = std_values[column]\n",
    "    result[column] = f\"{x:.4f} ± {y:.6f}\"\n",
    "\n",
    "# Display the \"x ± y\" representation for each column\n",
    "for column, value in result.items():\n",
    "    print(f\"{column}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a97659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ddc413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f0253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c200048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624a314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1649804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe425b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74541f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_higher_state1 = label[len(label)-1]  # Replace with your desired initial state\n",
    "prev_higher_state2 = label[len(label)-2]  # Replace with your desired initial state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b7cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_state =  la[len(train_data)-1] # Replace with your desired initial state\n",
    "prev_state1=  la[len(train_data)-2] # Replace with your desired initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e407b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res = []\n",
    "states_higher = np.unique(label)\n",
    "states = np.unique(df1['Task Domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f60f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predictions = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5292717",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_data[:total_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce9556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pred_res = []\n",
    "no_predict = total_predictions  # Total number of predictions you want to make\n",
    "\n",
    "# Prediction loop\n",
    "while no_predict > 0:\n",
    "    # Predict the next state at the higher level\n",
    "    higher_transition_probs = htm[prev_higher_state2][prev_higher_state1]\n",
    "    \n",
    "    # Normalize transition probabilities if the sum is not zero\n",
    "    if np.sum(higher_transition_probs) > 0:\n",
    "        higher_transition_probs /= np.sum(higher_transition_probs)\n",
    "    else:\n",
    "        # If sum is close to zero, assign equal probabilities to all states\n",
    "        higher_transition_probs = np.ones(len(states_higher)) / len(states_higher)\n",
    "    \n",
    "    next_higher_state = np.random.choice(states_higher, p=higher_transition_probs)\n",
    "    \n",
    "    # Identify the model tuple for the selected higher-level state\n",
    "    selected_model = rep_time[0][next_higher_state]\n",
    "    \n",
    "    # Access the adjacency matrix and time duration for the selected model\n",
    "    model_adj_matrix, model_time_duration = selected_model\n",
    "    \n",
    "    # Calculate transition probabilities for the previous two states\n",
    "    transition_probs = model_adj_matrix[prev_state1][prev_state]\n",
    "\n",
    "    # Normalize transition probabilities if the sum is not zero\n",
    "    if np.sum(transition_probs) > 0:\n",
    "        transition_probs /= np.sum(transition_probs)\n",
    "\n",
    "        # Sample the next state based on transition probabilities\n",
    "        next_state = np.random.choice(states, p=transition_probs)\n",
    "    else:\n",
    "        # If sum is close to zero, randomly choose the next state\n",
    "        next_state = np.random.choice(states)\n",
    "\n",
    "    # Append the predicted state to the result\n",
    "    pred_res.append(next_state)\n",
    "\n",
    "    # Update the state variables for the next iteration\n",
    "    prev_higher_state2 = prev_higher_state1\n",
    "    prev_higher_state1 = next_higher_state\n",
    "    prev_state1 = prev_state\n",
    "    prev_state = next_state\n",
    "\n",
    "    no_predict -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0ca1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicted Data\n",
    "df_pred = pd.DataFrame(res_num, columns=['CPU_util','mem_util','net_in','net_out','disk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori = df_actual[len(train_data):len(train_data)+total_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b625a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = MinMaxScaler(feature_range=(0.10,0.25))\n",
    "df_pred_norm = pd.DataFrame(norm.fit_transform(df_pred), columns=df_pred.columns)\n",
    "ori_norm = pd.DataFrame(norm.fit_transform(ori), columns=ori.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import math\n",
    "\n",
    "# Assuming df_pred and ori are your dataframes\n",
    "\n",
    "# Select the common columns for comparison\n",
    "common_columns = df_pred_norm.columns.intersection(ori_norm.columns)\n",
    "\n",
    "# Calculate MSE for each feature\n",
    "mse_values = {}\n",
    "mae_values = {}\n",
    "mape_values = {}\n",
    "rmse_values = {}\n",
    "for column in common_columns:\n",
    "    mse_values[column] = mean_squared_error(ori_norm[column], df_pred_norm[column])\n",
    "    mae_values[column] = mean_absolute_error(ori_norm[column], df_pred_norm[column])\n",
    "    mape_values[column] = mean_absolute_percentage_error(ori_norm[column], df_pred_norm[column])\n",
    "    rmse_values[column] = mean_squared_error(ori_norm[column], df_pred_norm[column], squared = False)\n",
    "# Calculate the average MSE\n",
    "average_mse = np.mean(list(mse_values.values()))\n",
    "average_mae = np.mean(list(mae_values.values()))\n",
    "average_mape = np.mean(list(mape_values.values()))\n",
    "average_rmse = np.mean(list(rmse_values.values()))\n",
    "\n",
    "# Print feature-wise MSE and average MSE\n",
    "print(\"Feature-wise MSE:\")\n",
    "for column, mse in mse_values.items():\n",
    "    print(f\"{column}: {mse:.6f}\")\n",
    "print(\"\\nAverage MSE:\", average_mse)\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print feature-wise MSE and average MSE\n",
    "print(\"Feature-wise MAE:\")\n",
    "for column, mae in mae_values.items():\n",
    "    print(f\"{column}: {mae:.6f}\")\n",
    "print(\"\\nAverage MAE:\", average_mae)\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Print feature-wise MSE and average MSE\n",
    "print(\"Feature-wise MAPE:\")\n",
    "for column, mape in mape_values.items():\n",
    "    print(f\"{column}: {mape:.6f}\")\n",
    "print(\"\\nAverage MAPE:\", average_mape)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Print feature-wise MSE and average MSE\n",
    "print(\"Feature-wise RMSE:\")\n",
    "for column, rmse in rmse_values.items():\n",
    "    print(f\"{column}: {rmse:.6f}\")\n",
    "print(\"\\nAverage RMSE:\", average_rmse)\n",
    "\n",
    "\n",
    "\n",
    "res_final = [average_mse,average_mae,average_mape,average_rmse]\n",
    "results_normalized.append([total_predictions, average_mse, average_mae, average_rmse, average_mape])\n",
    "print(res_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
